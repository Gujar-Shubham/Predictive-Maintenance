{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Valve Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5O394PHXxvV",
        "outputId": "9bbbc971-f9f1-4d60-98bd-eec656ac6efd"
      },
      "source": [
        "#Install non-standard packages (assuming jupyter notebook)\n",
        "!pip install shap\n",
        "!pip install lime\n",
        "!pip install eli5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting shap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f4/c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3/shap-0.39.0.tar.gz (356kB)\n",
            "\r\u001b[K     |█                               | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 12.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 245kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 276kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 286kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 296kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 307kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 317kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 327kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 337kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 348kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (54.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491624 sha256=8d9a6c7731a48a13e9d754565d7ba0a1fd06317a01c7018a2ecb34c1d6e5d2e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/27/f5/a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283\n",
            "Successfully built shap\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.39.0 slicer-0.0.7\n",
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp37-none-any.whl size=283846 sha256=ecac0db8cab6b6a44a5e431a76b6fcd29b44ca73f1df6308dbd54acd19a3e78d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n",
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/54/04cab6e1c0ae535bec93f795d8403fdf6caf66fa5a6512263202dbb14ea6/eli5-0.11.0-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (20.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "_nU6S35l6I8P",
        "outputId": "7d581457-d581-4a06-b270-e0dfa33cb0a4"
      },
      "source": [
        "# load the dataset \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "data = pd.read_excel('/content/drive/MyDrive/Pump Predictive Maintenance/Condition Hydraulic Pump/condition Hydraulic.xlsx')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>cycle_id</th>\n",
              "      <th>date</th>\n",
              "      <th>PS1</th>\n",
              "      <th>PS2</th>\n",
              "      <th>PS3</th>\n",
              "      <th>PS4</th>\n",
              "      <th>PS5</th>\n",
              "      <th>PS6</th>\n",
              "      <th>FS1</th>\n",
              "      <th>FS2</th>\n",
              "      <th>TS1</th>\n",
              "      <th>TS2</th>\n",
              "      <th>TS3</th>\n",
              "      <th>TS4</th>\n",
              "      <th>P1</th>\n",
              "      <th>VS1</th>\n",
              "      <th>CE1</th>\n",
              "      <th>CP1</th>\n",
              "      <th>SE1</th>\n",
              "      <th>cooler</th>\n",
              "      <th>valve</th>\n",
              "      <th>leakage</th>\n",
              "      <th>accumulator</th>\n",
              "      <th>stable</th>\n",
              "      <th>rul</th>\n",
              "      <th>label1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-01-01 00:00:00</td>\n",
              "      <td>160.673492</td>\n",
              "      <td>109.466914</td>\n",
              "      <td>1.991475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.842170</td>\n",
              "      <td>9.728097</td>\n",
              "      <td>6.709815</td>\n",
              "      <td>10.304592</td>\n",
              "      <td>35.621983</td>\n",
              "      <td>40.978767</td>\n",
              "      <td>38.471017</td>\n",
              "      <td>31.745250</td>\n",
              "      <td>2538.929167</td>\n",
              "      <td>0.576950</td>\n",
              "      <td>39.601350</td>\n",
              "      <td>1.862750</td>\n",
              "      <td>59.157183</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>35.166667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2019-01-01 00:10:00</td>\n",
              "      <td>160.603320</td>\n",
              "      <td>109.354890</td>\n",
              "      <td>1.976234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.635142</td>\n",
              "      <td>9.529488</td>\n",
              "      <td>6.715315</td>\n",
              "      <td>10.403098</td>\n",
              "      <td>36.676967</td>\n",
              "      <td>41.532767</td>\n",
              "      <td>38.978967</td>\n",
              "      <td>34.493867</td>\n",
              "      <td>2531.498900</td>\n",
              "      <td>0.565850</td>\n",
              "      <td>25.786433</td>\n",
              "      <td>1.255550</td>\n",
              "      <td>59.335617</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2019-01-01 00:20:00</td>\n",
              "      <td>160.347720</td>\n",
              "      <td>109.158845</td>\n",
              "      <td>1.972224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.530548</td>\n",
              "      <td>9.427949</td>\n",
              "      <td>6.718522</td>\n",
              "      <td>10.366250</td>\n",
              "      <td>37.880800</td>\n",
              "      <td>42.442450</td>\n",
              "      <td>39.631950</td>\n",
              "      <td>35.646150</td>\n",
              "      <td>2519.928000</td>\n",
              "      <td>0.576533</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.113217</td>\n",
              "      <td>59.543150</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>34.833333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-01-01 00:30:00</td>\n",
              "      <td>160.188088</td>\n",
              "      <td>109.064807</td>\n",
              "      <td>1.946575</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.438827</td>\n",
              "      <td>9.337430</td>\n",
              "      <td>6.720565</td>\n",
              "      <td>10.302678</td>\n",
              "      <td>38.879050</td>\n",
              "      <td>43.403983</td>\n",
              "      <td>40.403383</td>\n",
              "      <td>36.579467</td>\n",
              "      <td>2511.541633</td>\n",
              "      <td>0.569267</td>\n",
              "      <td>20.459817</td>\n",
              "      <td>1.062150</td>\n",
              "      <td>59.794900</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>34.666667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2019-01-01 00:40:00</td>\n",
              "      <td>160.000472</td>\n",
              "      <td>108.931434</td>\n",
              "      <td>1.922707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.358762</td>\n",
              "      <td>9.260636</td>\n",
              "      <td>6.690308</td>\n",
              "      <td>10.237750</td>\n",
              "      <td>39.803917</td>\n",
              "      <td>44.332750</td>\n",
              "      <td>41.310550</td>\n",
              "      <td>37.427900</td>\n",
              "      <td>2503.449500</td>\n",
              "      <td>0.577367</td>\n",
              "      <td>19.787017</td>\n",
              "      <td>1.070467</td>\n",
              "      <td>59.455267</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>34.500000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  cycle_id                date  ...  stable        rul  label1\n",
              "0           0         1 2019-01-01 00:00:00  ...       1  35.166667       0\n",
              "1           1         2 2019-01-01 00:10:00  ...       1  35.000000       0\n",
              "2           2         3 2019-01-01 00:20:00  ...       1  34.833333       0\n",
              "3           3         4 2019-01-01 00:30:00  ...       1  34.666667       0\n",
              "4           4         5 2019-01-01 00:40:00  ...       1  34.500000       0\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AFUZ6PRBI7l"
      },
      "source": [
        "df = pd.DataFrame(data, columns=['PS1','PS3', 'PS4', 'PS5', 'FS1', 'FS2', 'TS1', 'P1', 'VS1', 'CE1', 'CP1', 'SE1', 'valve'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "mlMkCE7QBN6M",
        "outputId": "82f91b21-e586-4cb6-e3a3-6319fa15ee99"
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PS1</th>\n",
              "      <th>PS3</th>\n",
              "      <th>PS4</th>\n",
              "      <th>PS5</th>\n",
              "      <th>FS1</th>\n",
              "      <th>FS2</th>\n",
              "      <th>TS1</th>\n",
              "      <th>P1</th>\n",
              "      <th>VS1</th>\n",
              "      <th>CE1</th>\n",
              "      <th>CP1</th>\n",
              "      <th>SE1</th>\n",
              "      <th>valve</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>160.673492</td>\n",
              "      <td>1.991475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.842170</td>\n",
              "      <td>6.709815</td>\n",
              "      <td>10.304592</td>\n",
              "      <td>35.621983</td>\n",
              "      <td>2538.929167</td>\n",
              "      <td>0.576950</td>\n",
              "      <td>39.601350</td>\n",
              "      <td>1.862750</td>\n",
              "      <td>59.157183</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>160.603320</td>\n",
              "      <td>1.976234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.635142</td>\n",
              "      <td>6.715315</td>\n",
              "      <td>10.403098</td>\n",
              "      <td>36.676967</td>\n",
              "      <td>2531.498900</td>\n",
              "      <td>0.565850</td>\n",
              "      <td>25.786433</td>\n",
              "      <td>1.255550</td>\n",
              "      <td>59.335617</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>160.347720</td>\n",
              "      <td>1.972224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.530548</td>\n",
              "      <td>6.718522</td>\n",
              "      <td>10.366250</td>\n",
              "      <td>37.880800</td>\n",
              "      <td>2519.928000</td>\n",
              "      <td>0.576533</td>\n",
              "      <td>25.786433</td>\n",
              "      <td>1.113217</td>\n",
              "      <td>59.543150</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>160.188088</td>\n",
              "      <td>1.946575</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.438827</td>\n",
              "      <td>6.720565</td>\n",
              "      <td>10.302678</td>\n",
              "      <td>38.879050</td>\n",
              "      <td>2511.541633</td>\n",
              "      <td>0.569267</td>\n",
              "      <td>20.459817</td>\n",
              "      <td>1.062150</td>\n",
              "      <td>59.794900</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>160.000472</td>\n",
              "      <td>1.922707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.358762</td>\n",
              "      <td>6.690308</td>\n",
              "      <td>10.237750</td>\n",
              "      <td>39.803917</td>\n",
              "      <td>2503.449500</td>\n",
              "      <td>0.577367</td>\n",
              "      <td>19.787017</td>\n",
              "      <td>1.070467</td>\n",
              "      <td>59.455267</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          PS1       PS3  PS4       PS5  ...        CE1       CP1        SE1  valve\n",
              "0  160.673492  1.991475  0.0  9.842170  ...  39.601350  1.862750  59.157183    100\n",
              "1  160.603320  1.976234  0.0  9.635142  ...  25.786433  1.255550  59.335617    100\n",
              "2  160.347720  1.972224  0.0  9.530548  ...  25.786433  1.113217  59.543150    100\n",
              "3  160.188088  1.946575  0.0  9.438827  ...  20.459817  1.062150  59.794900    100\n",
              "4  160.000472  1.922707  0.0  9.358762  ...  19.787017  1.070467  59.455267    100\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f0RhofvBQD7",
        "outputId": "072a508e-bb98-4bfe-9e7a-8edd9a822ba3"
      },
      "source": [
        "df['valve'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([100,  73,  80,  90])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05LC5bctBRzR"
      },
      "source": [
        "X = df.iloc[:, :12]\n",
        "y = df.iloc[:, 12]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtApho1rBW_f"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "#test_y = le.fit_transform(test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMu1KQlS6AAw"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0HOe2j9Bchb"
      },
      "source": [
        "import keras\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes = 4)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlvovIiBBfU6"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idfYelDNBhS5"
      },
      "source": [
        "# Part 2 - Now let's make the ANN!\n",
        "# import necessary modules  \n",
        "import pandas  as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# Importing the Keras libraries and packages\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_iJBOWVBi6K"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "model = Sequential()\n",
        "model.add(Dense(12, activation='relu', input_dim=12))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "sgd = SGD(lr = 0.001, decay = 1e-6, momentum = 0.9, nesterov=True)\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSy4GjwtBknj",
        "outputId": "54d61fcd-9f6a-47d3-bf19-3daffc421439"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs = 200, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "56/56 [==============================] - 1s 881us/step - loss: 1.3467 - accuracy: 0.4256\n",
            "Epoch 2/200\n",
            "56/56 [==============================] - 0s 864us/step - loss: 1.2682 - accuracy: 0.5057\n",
            "Epoch 3/200\n",
            "56/56 [==============================] - 0s 822us/step - loss: 1.2333 - accuracy: 0.5183\n",
            "Epoch 4/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.2227 - accuracy: 0.4994\n",
            "Epoch 5/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1938 - accuracy: 0.5173\n",
            "Epoch 6/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1785 - accuracy: 0.5215\n",
            "Epoch 7/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1621 - accuracy: 0.5262\n",
            "Epoch 8/200\n",
            "56/56 [==============================] - 0s 933us/step - loss: 1.1789 - accuracy: 0.5079\n",
            "Epoch 9/200\n",
            "56/56 [==============================] - 0s 996us/step - loss: 1.1600 - accuracy: 0.5125\n",
            "Epoch 10/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1469 - accuracy: 0.5197\n",
            "Epoch 11/200\n",
            "56/56 [==============================] - 0s 951us/step - loss: 1.1604 - accuracy: 0.5093\n",
            "Epoch 12/200\n",
            "56/56 [==============================] - 0s 972us/step - loss: 1.1130 - accuracy: 0.5379\n",
            "Epoch 13/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1569 - accuracy: 0.4941\n",
            "Epoch 14/200\n",
            "56/56 [==============================] - 0s 890us/step - loss: 1.1426 - accuracy: 0.5002\n",
            "Epoch 15/200\n",
            "56/56 [==============================] - 0s 850us/step - loss: 1.1244 - accuracy: 0.5141\n",
            "Epoch 16/200\n",
            "56/56 [==============================] - 0s 938us/step - loss: 1.1438 - accuracy: 0.4960\n",
            "Epoch 17/200\n",
            "56/56 [==============================] - 0s 893us/step - loss: 1.1263 - accuracy: 0.5084\n",
            "Epoch 18/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1300 - accuracy: 0.5145\n",
            "Epoch 19/200\n",
            "56/56 [==============================] - 0s 905us/step - loss: 1.1227 - accuracy: 0.5007\n",
            "Epoch 20/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1046 - accuracy: 0.5214\n",
            "Epoch 21/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0976 - accuracy: 0.5178\n",
            "Epoch 22/200\n",
            "56/56 [==============================] - 0s 915us/step - loss: 1.1224 - accuracy: 0.5039\n",
            "Epoch 23/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0963 - accuracy: 0.4998\n",
            "Epoch 24/200\n",
            "56/56 [==============================] - 0s 864us/step - loss: 1.0870 - accuracy: 0.5165\n",
            "Epoch 25/200\n",
            "56/56 [==============================] - 0s 852us/step - loss: 1.1045 - accuracy: 0.5098\n",
            "Epoch 26/200\n",
            "56/56 [==============================] - 0s 899us/step - loss: 1.0972 - accuracy: 0.5126\n",
            "Epoch 27/200\n",
            "56/56 [==============================] - 0s 881us/step - loss: 1.0922 - accuracy: 0.5293\n",
            "Epoch 28/200\n",
            "56/56 [==============================] - 0s 631us/step - loss: 1.1080 - accuracy: 0.5225\n",
            "Epoch 29/200\n",
            "56/56 [==============================] - 0s 628us/step - loss: 1.0880 - accuracy: 0.5319\n",
            "Epoch 30/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1077 - accuracy: 0.5133\n",
            "Epoch 31/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1127 - accuracy: 0.5185\n",
            "Epoch 32/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1049 - accuracy: 0.5218\n",
            "Epoch 33/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.1241 - accuracy: 0.5072\n",
            "Epoch 34/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0882 - accuracy: 0.5322\n",
            "Epoch 35/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0753 - accuracy: 0.5503\n",
            "Epoch 36/200\n",
            "56/56 [==============================] - 0s 741us/step - loss: 1.0681 - accuracy: 0.5417\n",
            "Epoch 37/200\n",
            "56/56 [==============================] - 0s 873us/step - loss: 1.0736 - accuracy: 0.5521\n",
            "Epoch 38/200\n",
            "56/56 [==============================] - 0s 890us/step - loss: 1.0764 - accuracy: 0.5507\n",
            "Epoch 39/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0850 - accuracy: 0.5375\n",
            "Epoch 40/200\n",
            "56/56 [==============================] - 0s 879us/step - loss: 1.0693 - accuracy: 0.5401\n",
            "Epoch 41/200\n",
            "56/56 [==============================] - 0s 938us/step - loss: 1.0849 - accuracy: 0.5400\n",
            "Epoch 42/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0739 - accuracy: 0.5461\n",
            "Epoch 43/200\n",
            "56/56 [==============================] - 0s 876us/step - loss: 1.0734 - accuracy: 0.5564\n",
            "Epoch 44/200\n",
            "56/56 [==============================] - 0s 875us/step - loss: 1.0905 - accuracy: 0.5446\n",
            "Epoch 45/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0801 - accuracy: 0.5385\n",
            "Epoch 46/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0751 - accuracy: 0.5665\n",
            "Epoch 47/200\n",
            "56/56 [==============================] - 0s 911us/step - loss: 1.0775 - accuracy: 0.5431\n",
            "Epoch 48/200\n",
            "56/56 [==============================] - 0s 980us/step - loss: 1.0732 - accuracy: 0.5524\n",
            "Epoch 49/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0839 - accuracy: 0.5590\n",
            "Epoch 50/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0684 - accuracy: 0.5574\n",
            "Epoch 51/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0946 - accuracy: 0.5357\n",
            "Epoch 52/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0823 - accuracy: 0.5341\n",
            "Epoch 53/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0782 - accuracy: 0.5562\n",
            "Epoch 54/200\n",
            "56/56 [==============================] - 0s 874us/step - loss: 1.0679 - accuracy: 0.5452\n",
            "Epoch 55/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0844 - accuracy: 0.5406\n",
            "Epoch 56/200\n",
            "56/56 [==============================] - 0s 947us/step - loss: 1.0857 - accuracy: 0.5381\n",
            "Epoch 57/200\n",
            "56/56 [==============================] - 0s 983us/step - loss: 1.0614 - accuracy: 0.5469\n",
            "Epoch 58/200\n",
            "56/56 [==============================] - 0s 903us/step - loss: 1.0613 - accuracy: 0.5467\n",
            "Epoch 59/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0896 - accuracy: 0.5265\n",
            "Epoch 60/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0848 - accuracy: 0.5336\n",
            "Epoch 61/200\n",
            "56/56 [==============================] - 0s 842us/step - loss: 1.0704 - accuracy: 0.5241\n",
            "Epoch 62/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0604 - accuracy: 0.5550\n",
            "Epoch 63/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0752 - accuracy: 0.5389\n",
            "Epoch 64/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0695 - accuracy: 0.5447\n",
            "Epoch 65/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0853 - accuracy: 0.5355\n",
            "Epoch 66/200\n",
            "56/56 [==============================] - 0s 943us/step - loss: 1.0887 - accuracy: 0.5349\n",
            "Epoch 67/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0749 - accuracy: 0.5281\n",
            "Epoch 68/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0513 - accuracy: 0.5491\n",
            "Epoch 69/200\n",
            "56/56 [==============================] - 0s 964us/step - loss: 1.0660 - accuracy: 0.5420\n",
            "Epoch 70/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0879 - accuracy: 0.5294\n",
            "Epoch 71/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0581 - accuracy: 0.5415\n",
            "Epoch 72/200\n",
            "56/56 [==============================] - 0s 865us/step - loss: 1.0682 - accuracy: 0.5277\n",
            "Epoch 73/200\n",
            "56/56 [==============================] - 0s 968us/step - loss: 1.0656 - accuracy: 0.5387\n",
            "Epoch 74/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0440 - accuracy: 0.5402\n",
            "Epoch 75/200\n",
            "56/56 [==============================] - 0s 897us/step - loss: 1.0818 - accuracy: 0.5366\n",
            "Epoch 76/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0907 - accuracy: 0.5217\n",
            "Epoch 77/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0580 - accuracy: 0.5378\n",
            "Epoch 78/200\n",
            "56/56 [==============================] - 0s 866us/step - loss: 1.0575 - accuracy: 0.5317\n",
            "Epoch 79/200\n",
            "56/56 [==============================] - 0s 939us/step - loss: 1.0665 - accuracy: 0.5201\n",
            "Epoch 80/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0873 - accuracy: 0.5327\n",
            "Epoch 81/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0498 - accuracy: 0.5405\n",
            "Epoch 82/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0409 - accuracy: 0.5486\n",
            "Epoch 83/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0745 - accuracy: 0.5221\n",
            "Epoch 84/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0557 - accuracy: 0.5430\n",
            "Epoch 85/200\n",
            "56/56 [==============================] - 0s 934us/step - loss: 1.0487 - accuracy: 0.5478\n",
            "Epoch 86/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0633 - accuracy: 0.5432\n",
            "Epoch 87/200\n",
            "56/56 [==============================] - 0s 890us/step - loss: 1.0640 - accuracy: 0.5291\n",
            "Epoch 88/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0548 - accuracy: 0.5456\n",
            "Epoch 89/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0485 - accuracy: 0.5493\n",
            "Epoch 90/200\n",
            "56/56 [==============================] - 0s 869us/step - loss: 1.0404 - accuracy: 0.5403\n",
            "Epoch 91/200\n",
            "56/56 [==============================] - 0s 967us/step - loss: 1.0606 - accuracy: 0.5301\n",
            "Epoch 92/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0519 - accuracy: 0.5340\n",
            "Epoch 93/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0545 - accuracy: 0.5220\n",
            "Epoch 94/200\n",
            "56/56 [==============================] - 0s 884us/step - loss: 1.0505 - accuracy: 0.5433\n",
            "Epoch 95/200\n",
            "56/56 [==============================] - 0s 881us/step - loss: 1.0493 - accuracy: 0.5470\n",
            "Epoch 96/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0349 - accuracy: 0.5573\n",
            "Epoch 97/200\n",
            "56/56 [==============================] - 0s 883us/step - loss: 1.0322 - accuracy: 0.5487\n",
            "Epoch 98/200\n",
            "56/56 [==============================] - 0s 620us/step - loss: 1.0385 - accuracy: 0.5425\n",
            "Epoch 99/200\n",
            "56/56 [==============================] - 0s 610us/step - loss: 1.0676 - accuracy: 0.5275\n",
            "Epoch 100/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0388 - accuracy: 0.5587\n",
            "Epoch 101/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0529 - accuracy: 0.5366\n",
            "Epoch 102/200\n",
            "56/56 [==============================] - 0s 941us/step - loss: 1.0348 - accuracy: 0.5589\n",
            "Epoch 103/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0347 - accuracy: 0.5428\n",
            "Epoch 104/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0397 - accuracy: 0.5500\n",
            "Epoch 105/200\n",
            "56/56 [==============================] - 0s 939us/step - loss: 1.0274 - accuracy: 0.5525\n",
            "Epoch 106/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0705 - accuracy: 0.5270\n",
            "Epoch 107/200\n",
            "56/56 [==============================] - 0s 887us/step - loss: 1.0326 - accuracy: 0.5572\n",
            "Epoch 108/200\n",
            "56/56 [==============================] - 0s 979us/step - loss: 1.0596 - accuracy: 0.5319\n",
            "Epoch 109/200\n",
            "56/56 [==============================] - 0s 944us/step - loss: 1.0227 - accuracy: 0.5579\n",
            "Epoch 110/200\n",
            "56/56 [==============================] - 0s 909us/step - loss: 1.0319 - accuracy: 0.5636\n",
            "Epoch 111/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0413 - accuracy: 0.5481\n",
            "Epoch 112/200\n",
            "56/56 [==============================] - 0s 841us/step - loss: 1.0501 - accuracy: 0.5543\n",
            "Epoch 113/200\n",
            "56/56 [==============================] - 0s 939us/step - loss: 1.0415 - accuracy: 0.5390\n",
            "Epoch 114/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0176 - accuracy: 0.5669\n",
            "Epoch 115/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0619 - accuracy: 0.5319\n",
            "Epoch 116/200\n",
            "56/56 [==============================] - 0s 909us/step - loss: 1.0441 - accuracy: 0.5501\n",
            "Epoch 117/200\n",
            "56/56 [==============================] - 0s 972us/step - loss: 1.0402 - accuracy: 0.5431\n",
            "Epoch 118/200\n",
            "56/56 [==============================] - 0s 853us/step - loss: 1.0265 - accuracy: 0.5518\n",
            "Epoch 119/200\n",
            "56/56 [==============================] - 0s 876us/step - loss: 1.0592 - accuracy: 0.5483\n",
            "Epoch 120/200\n",
            "56/56 [==============================] - 0s 852us/step - loss: 1.0371 - accuracy: 0.5493\n",
            "Epoch 121/200\n",
            "56/56 [==============================] - 0s 889us/step - loss: 1.0392 - accuracy: 0.5491\n",
            "Epoch 122/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0311 - accuracy: 0.5499\n",
            "Epoch 123/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0092 - accuracy: 0.5716\n",
            "Epoch 124/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0379 - accuracy: 0.5540\n",
            "Epoch 125/200\n",
            "56/56 [==============================] - 0s 898us/step - loss: 1.0111 - accuracy: 0.5659\n",
            "Epoch 126/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0738 - accuracy: 0.5228\n",
            "Epoch 127/200\n",
            "56/56 [==============================] - 0s 896us/step - loss: 1.0364 - accuracy: 0.5509\n",
            "Epoch 128/200\n",
            "56/56 [==============================] - 0s 876us/step - loss: 1.0152 - accuracy: 0.5607\n",
            "Epoch 129/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0254 - accuracy: 0.5583\n",
            "Epoch 130/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0200 - accuracy: 0.5506\n",
            "Epoch 131/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0202 - accuracy: 0.5615\n",
            "Epoch 132/200\n",
            "56/56 [==============================] - 0s 954us/step - loss: 1.0060 - accuracy: 0.5644\n",
            "Epoch 133/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0286 - accuracy: 0.5549\n",
            "Epoch 134/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0369 - accuracy: 0.5396\n",
            "Epoch 135/200\n",
            "56/56 [==============================] - 0s 871us/step - loss: 1.0170 - accuracy: 0.5615\n",
            "Epoch 136/200\n",
            "56/56 [==============================] - 0s 719us/step - loss: 1.0258 - accuracy: 0.5450\n",
            "Epoch 137/200\n",
            "56/56 [==============================] - 0s 694us/step - loss: 1.0241 - accuracy: 0.5443\n",
            "Epoch 138/200\n",
            "56/56 [==============================] - 0s 641us/step - loss: 1.0319 - accuracy: 0.5425\n",
            "Epoch 139/200\n",
            "56/56 [==============================] - 0s 907us/step - loss: 1.0249 - accuracy: 0.5495\n",
            "Epoch 140/200\n",
            "56/56 [==============================] - 0s 939us/step - loss: 1.0223 - accuracy: 0.5465\n",
            "Epoch 141/200\n",
            "56/56 [==============================] - 0s 900us/step - loss: 1.0135 - accuracy: 0.5534\n",
            "Epoch 142/200\n",
            "56/56 [==============================] - 0s 939us/step - loss: 0.9972 - accuracy: 0.5593\n",
            "Epoch 143/200\n",
            "56/56 [==============================] - 0s 901us/step - loss: 1.0069 - accuracy: 0.5657\n",
            "Epoch 144/200\n",
            "56/56 [==============================] - 0s 869us/step - loss: 0.9985 - accuracy: 0.5744\n",
            "Epoch 145/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0027 - accuracy: 0.5734\n",
            "Epoch 146/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9985 - accuracy: 0.5578\n",
            "Epoch 147/200\n",
            "56/56 [==============================] - 0s 942us/step - loss: 1.0091 - accuracy: 0.5725\n",
            "Epoch 148/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0023 - accuracy: 0.5686\n",
            "Epoch 149/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0131 - accuracy: 0.5617\n",
            "Epoch 150/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9915 - accuracy: 0.5766\n",
            "Epoch 151/200\n",
            "56/56 [==============================] - 0s 894us/step - loss: 0.9920 - accuracy: 0.5630\n",
            "Epoch 152/200\n",
            "56/56 [==============================] - 0s 890us/step - loss: 0.9798 - accuracy: 0.5864\n",
            "Epoch 153/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9779 - accuracy: 0.5755\n",
            "Epoch 154/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9926 - accuracy: 0.5656\n",
            "Epoch 155/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9891 - accuracy: 0.5813\n",
            "Epoch 156/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0029 - accuracy: 0.5637\n",
            "Epoch 157/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9821 - accuracy: 0.5877\n",
            "Epoch 158/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9863 - accuracy: 0.5731\n",
            "Epoch 159/200\n",
            "56/56 [==============================] - 0s 944us/step - loss: 1.0171 - accuracy: 0.5652\n",
            "Epoch 160/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9807 - accuracy: 0.5840\n",
            "Epoch 161/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 1.0129 - accuracy: 0.5636\n",
            "Epoch 162/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9986 - accuracy: 0.5564\n",
            "Epoch 163/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9967 - accuracy: 0.5595\n",
            "Epoch 164/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9895 - accuracy: 0.5787\n",
            "Epoch 165/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9782 - accuracy: 0.5741\n",
            "Epoch 166/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9866 - accuracy: 0.5906\n",
            "Epoch 167/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9651 - accuracy: 0.5844\n",
            "Epoch 168/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9767 - accuracy: 0.5903\n",
            "Epoch 169/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9964 - accuracy: 0.5764\n",
            "Epoch 170/200\n",
            "56/56 [==============================] - 0s 902us/step - loss: 0.9977 - accuracy: 0.5769\n",
            "Epoch 171/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9745 - accuracy: 0.5847\n",
            "Epoch 172/200\n",
            "56/56 [==============================] - 0s 781us/step - loss: 0.9805 - accuracy: 0.5705\n",
            "Epoch 173/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9944 - accuracy: 0.5823\n",
            "Epoch 174/200\n",
            "56/56 [==============================] - 0s 880us/step - loss: 0.9926 - accuracy: 0.5758\n",
            "Epoch 175/200\n",
            "56/56 [==============================] - 0s 868us/step - loss: 0.9566 - accuracy: 0.5919\n",
            "Epoch 176/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9878 - accuracy: 0.5738\n",
            "Epoch 177/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9732 - accuracy: 0.5867\n",
            "Epoch 178/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9859 - accuracy: 0.5678\n",
            "Epoch 179/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9573 - accuracy: 0.5913\n",
            "Epoch 180/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9893 - accuracy: 0.5886\n",
            "Epoch 181/200\n",
            "56/56 [==============================] - 0s 998us/step - loss: 0.9640 - accuracy: 0.5948\n",
            "Epoch 182/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9680 - accuracy: 0.5818\n",
            "Epoch 183/200\n",
            "56/56 [==============================] - 0s 667us/step - loss: 1.0044 - accuracy: 0.5778\n",
            "Epoch 184/200\n",
            "56/56 [==============================] - 0s 878us/step - loss: 0.9515 - accuracy: 0.5950\n",
            "Epoch 185/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9538 - accuracy: 0.5953\n",
            "Epoch 186/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9523 - accuracy: 0.5932\n",
            "Epoch 187/200\n",
            "56/56 [==============================] - 0s 900us/step - loss: 0.9563 - accuracy: 0.5886\n",
            "Epoch 188/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9712 - accuracy: 0.5712\n",
            "Epoch 189/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9519 - accuracy: 0.5954\n",
            "Epoch 190/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9560 - accuracy: 0.6006\n",
            "Epoch 191/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9609 - accuracy: 0.5866\n",
            "Epoch 192/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9496 - accuracy: 0.6033\n",
            "Epoch 193/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9550 - accuracy: 0.5898\n",
            "Epoch 194/200\n",
            "56/56 [==============================] - 0s 943us/step - loss: 0.9279 - accuracy: 0.6035\n",
            "Epoch 195/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9452 - accuracy: 0.5797\n",
            "Epoch 196/200\n",
            "56/56 [==============================] - 0s 899us/step - loss: 0.9555 - accuracy: 0.6060\n",
            "Epoch 197/200\n",
            "56/56 [==============================] - 0s 943us/step - loss: 0.9407 - accuracy: 0.5898\n",
            "Epoch 198/200\n",
            "56/56 [==============================] - 0s 761us/step - loss: 0.9304 - accuracy: 0.6194\n",
            "Epoch 199/200\n",
            "56/56 [==============================] - 0s 906us/step - loss: 0.9105 - accuracy: 0.6158\n",
            "Epoch 200/200\n",
            "56/56 [==============================] - 0s 1ms/step - loss: 0.9089 - accuracy: 0.6291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxCYaTeBmdQ",
        "outputId": "d6093d36-5870-4742-e2d5-230842826ee4"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.9355047345161438\n",
            "Test accuracy: 0.6099773049354553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "4akpY96qYIH0",
        "outputId": "b2eaa038-41e6-4194-d3b1-97fbfa891726"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "perm = PermutationImportance(model, scoring='neg_mean_squared_error').fit(X_train,y_train)\n",
        "eli5.show_weights(perm, feature_names = X.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0655\n",
              "                \n",
              "                    &plusmn; 0.0029\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                SE1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 81.61%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0582\n",
              "                \n",
              "                    &plusmn; 0.0056\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 83.69%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0490\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                FS2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0302\n",
              "                \n",
              "                    &plusmn; 0.0025\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                VS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0281\n",
              "                \n",
              "                    &plusmn; 0.0025\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                CE1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 89.64%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0256\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS4\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 89.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0245\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                TS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.68%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0220\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                CP1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0146\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS5\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0092\n",
              "                \n",
              "                    &plusmn; 0.0022\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                P1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0091\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                FS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.17%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0086\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS3\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "nG3KdBxDYOa9",
        "outputId": "5395dd02-dbc1-4af0-88ad-dbdeab710b9b"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "from matplotlib import pyplot\n",
        "# perform permutation importance\n",
        "results = permutation_importance(model, X_train, y_train, scoring='neg_mean_squared_error')\n",
        "# get importance\n",
        "importance = results.importances_mean\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: 0, Score: 0.05939\n",
            "Feature: 1, Score: 0.00867\n",
            "Feature: 2, Score: 0.02594\n",
            "Feature: 3, Score: 0.01414\n",
            "Feature: 4, Score: 0.00863\n",
            "Feature: 5, Score: 0.05030\n",
            "Feature: 6, Score: 0.02550\n",
            "Feature: 7, Score: 0.00844\n",
            "Feature: 8, Score: 0.03121\n",
            "Feature: 9, Score: 0.02765\n",
            "Feature: 10, Score: 0.02109\n",
            "Feature: 11, Score: 0.06373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zepkE7D9B2GT",
        "outputId": "8a4adc74-dfe3-4e3f-d7d0-16df5c00c285"
      },
      "source": [
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test_class, y_pred_class))\n",
        "print(confusion_matrix(y_test_class, y_pred_class))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.69      0.61        72\n",
            "           1       0.00      0.00      0.00        72\n",
            "           2       0.00      0.00      0.00        72\n",
            "           3       0.63      0.97      0.77       225\n",
            "\n",
            "    accuracy                           0.61       441\n",
            "   macro avg       0.29      0.42      0.34       441\n",
            "weighted avg       0.41      0.61      0.49       441\n",
            "\n",
            "[[ 50   0   1  21]\n",
            " [ 28   0   1  43]\n",
            " [  9   0   0  63]\n",
            " [  6   0   0 219]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlT1M8hsCMfM"
      },
      "source": [
        "model.save(\"valve.h5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML56MUxxAC9C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44f43013-0797-43df-d854-695cf0ac1c03"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,mean_absolute_error\n",
        "from sklearn.tree import DecisionTreeClassifier    \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import accuracy_score,mean_absolute_error\n",
        "from sklearn import tree\n",
        "\n",
        "clf_gini = DecisionTreeClassifier(criterion = \"gini\",                # Criterion\n",
        "                                  max_depth =5 ,  \n",
        "                                  min_samples_split = 2, # Max Height of Tree\n",
        "                                  min_samples_leaf = 1,              # Maximum Leaf samples\n",
        "                                  random_state = 100)\n",
        "\n",
        "clf_gini.fit(X_train, y_train)\n",
        "y_pred_gini = clf_gini.predict(X_test)  \n",
        "\n",
        "print (\"Accuracy : \", accuracy_score(y_test,y_pred_gini)*100)         # Evaulating predictions with test labels\n",
        "print (\"Report : \",  classification_report(y_test, y_pred_gini))\n",
        "text_representation = tree.export_text(clf_gini, feature_names=X.columns.tolist())\n",
        "print(text_representation)\n",
        "# get importance\n",
        "importance = clf_gini.feature_importances_\n",
        "# summarize feature importance\n",
        "for feature_names,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (feature_names,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([x for x in range(len(importance))], importance, tick_label= X.columns)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  62.585034013605444\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "          73       0.41      0.93      0.57        72\n",
            "          80       0.68      0.21      0.32        72\n",
            "          90       0.46      0.08      0.14        72\n",
            "         100       0.78      0.84      0.81       225\n",
            "\n",
            "    accuracy                           0.63       441\n",
            "   macro avg       0.58      0.51      0.46       441\n",
            "weighted avg       0.65      0.63      0.58       441\n",
            "\n",
            "|--- SE1 <= 58.82\n",
            "|   |--- SE1 <= 29.91\n",
            "|   |   |--- PS1 <= 172.87\n",
            "|   |   |   |--- class: 80\n",
            "|   |   |--- PS1 >  172.87\n",
            "|   |   |   |--- SE1 <= 23.70\n",
            "|   |   |   |   |--- PS1 <= 180.58\n",
            "|   |   |   |   |   |--- class: 90\n",
            "|   |   |   |   |--- PS1 >  180.58\n",
            "|   |   |   |   |   |--- class: 73\n",
            "|   |   |   |--- SE1 >  23.70\n",
            "|   |   |   |   |--- VS1 <= 0.75\n",
            "|   |   |   |   |   |--- class: 73\n",
            "|   |   |   |   |--- VS1 >  0.75\n",
            "|   |   |   |   |   |--- class: 73\n",
            "|   |--- SE1 >  29.91\n",
            "|   |   |--- PS5 <= 9.95\n",
            "|   |   |   |--- FS1 <= 6.54\n",
            "|   |   |   |   |--- SE1 <= 56.91\n",
            "|   |   |   |   |   |--- class: 73\n",
            "|   |   |   |   |--- SE1 >  56.91\n",
            "|   |   |   |   |   |--- class: 100\n",
            "|   |   |   |--- FS1 >  6.54\n",
            "|   |   |   |   |--- FS1 <= 6.67\n",
            "|   |   |   |   |   |--- class: 73\n",
            "|   |   |   |   |--- FS1 >  6.67\n",
            "|   |   |   |   |   |--- class: 80\n",
            "|   |   |--- PS5 >  9.95\n",
            "|   |   |   |--- class: 100\n",
            "|--- SE1 >  58.82\n",
            "|   |--- PS5 <= 8.50\n",
            "|   |   |--- SE1 <= 59.41\n",
            "|   |   |   |--- FS1 <= 6.56\n",
            "|   |   |   |   |--- class: 73\n",
            "|   |   |   |--- FS1 >  6.56\n",
            "|   |   |   |   |--- TS1 <= 56.78\n",
            "|   |   |   |   |   |--- class: 80\n",
            "|   |   |   |   |--- TS1 >  56.78\n",
            "|   |   |   |   |   |--- class: 100\n",
            "|   |   |--- SE1 >  59.41\n",
            "|   |   |   |--- PS1 <= 156.38\n",
            "|   |   |   |   |--- FS2 <= 9.04\n",
            "|   |   |   |   |   |--- class: 100\n",
            "|   |   |   |   |--- FS2 >  9.04\n",
            "|   |   |   |   |   |--- class: 100\n",
            "|   |   |   |--- PS1 >  156.38\n",
            "|   |   |   |   |--- FS1 <= 6.59\n",
            "|   |   |   |   |   |--- class: 80\n",
            "|   |   |   |   |--- FS1 >  6.59\n",
            "|   |   |   |   |   |--- class: 90\n",
            "|   |--- PS5 >  8.50\n",
            "|   |   |--- PS1 <= 158.68\n",
            "|   |   |   |--- FS1 <= 6.56\n",
            "|   |   |   |   |--- class: 73\n",
            "|   |   |   |--- FS1 >  6.56\n",
            "|   |   |   |   |--- class: 100\n",
            "|   |   |--- PS1 >  158.68\n",
            "|   |   |   |--- TS1 <= 36.15\n",
            "|   |   |   |   |--- PS1 <= 161.24\n",
            "|   |   |   |   |   |--- class: 100\n",
            "|   |   |   |   |--- PS1 >  161.24\n",
            "|   |   |   |   |   |--- class: 90\n",
            "|   |   |   |--- TS1 >  36.15\n",
            "|   |   |   |   |--- PS1 <= 161.01\n",
            "|   |   |   |   |   |--- class: 100\n",
            "|   |   |   |   |--- PS1 >  161.01\n",
            "|   |   |   |   |   |--- class: 90\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                145.5189\n",
              "                \n",
              "                    &plusmn; 16.8176\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                SE1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 85.20%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                94.6212\n",
              "                \n",
              "                    &plusmn; 9.4380\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                FS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                23.8817\n",
              "                \n",
              "                    &plusmn; 6.5424\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS5\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.58%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                11.6594\n",
              "                \n",
              "                    &plusmn; 1.0369\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                6.2018\n",
              "                \n",
              "                    &plusmn; 0.6900\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                TS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                CP1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                CE1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                VS1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                P1\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                FS2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS4\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PS3\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqu0jty4bM3j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}